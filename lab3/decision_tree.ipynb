{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Lab 3 - drzewa decyzyjne\n",
    "\n",
    "Drzewa decyzyjne są klasyfikatorami dodatkowo ilustrującymi proces decyzyjny w sposób graficzny.\n",
    "\n",
    "## Przykładowe drzewo decyzyjne\n",
    "\n",
    "Poniższe drzewo decyzyjne ilustruje proces podejmowania decyzji odnośnie gry w tenisa w zależności od warunków pogodowych.\n",
    "\n",
    "![model_learning](img/id3_tennis.png)\n",
    "\n",
    "1. Jaką decyzję podejmiemy przy słonecznej pogodzie i wysokiej wilgotności powietrza?\n",
    "2. Jaką decyzję podejmiemy przy pogodzie pochmurnej i niskiej wilgotności powietrza?\n",
    "\n",
    "## Uczenie drzewa decyzyjnego\n",
    "\n",
    "Uczenie (formowanie) drzewa decyzyjnego odbywa się na podstawie danych w formie systemu decyzyjnego.\n",
    "\n",
    "Metodę uczenia drzewa decyzyjnego można uogólnić następującymi krokami:\n",
    "- znalezienie atrybutu w systemie treningowym atrybutu niosącego najwięcej informacji, a następnie podzielenie systemu na kategorie według tego atrybutu.\n",
    "- powtarzanie procesu do osiągnięcia pewnego założonego progu\n",
    "\n",
    "Do podziału systemu decyzyjnego na podkategorie można wykorzystać następujące metryki:\n",
    "- Zysk informacyjny\n",
    "- Niejednorodność Giniego\n",
    "\n",
    "### Zysk informacyjny\n",
    "\n",
    "Zysk informacyjny jest miarą zgodności badanego atrybutu z celem.\n",
    "\n",
    "Miarę zysku informacyjnego można wyrazić wzorem:\n",
    "\n",
    "$$Gain(S, A) = Entropy(S) - \\sum_{v \\in Values(A)} \\frac{|S_v|}{|S|} Entropy(S_v)$$\n",
    "\n",
    "gdzie:\n",
    "- S oznacza zbiór obiektów w systemie decyzyjnym\n",
    "- A oznacza badany atrybut\n",
    "- $$ Entropy(S) = \\sum_{i=1}^n -p_i log_2(p_i) $$, gdzie:\n",
    "    - $$n$$ oznacza liczbę klas decyzyjnych\n",
    "    - $$p_i$$ oznacza liczbę obiektów w i-tej klasie decyzyjnej\n",
    "\n",
    "### Niejednorodność Giniego\n",
    "\n",
    "Niejednorodność Giniego jest miarą probabilistyczną definiującą prawdopodobieństwo przydzielenia błędnej decyzji za pomocą\n",
    "badanego atrybutu, co można wyrazić następującym wzorem:\n",
    "\n",
    "$$I_{G}(A) = 1 - \\sum_{i=1}^n p(A_i)^2$$\n",
    "\n",
    "gdzie:\n",
    "- f oznacza badany atrybut\n",
    "- n oznacza liczbę wartości w badanym atrybucie\n",
    "- $$p(f_i)$$ oznacza prawdopodobieństwo wystąpienia wartości badanego atrybutu w i-tej klasie decyzyjnej\n",
    "\n",
    "Podczas wyznaczania podziału systemu decyzyjnego należy wybrać atrybut, dla którego wartośc zysku informacyjnego jest\n",
    "największa lub wartość niejednorodności Giniego jest najmniejsza.\n",
    "\n",
    "## Przykład uczenia drzewa decyzyjnego\n",
    "\n",
    "Rozważmy następujący system decyzyjny obrazujący cele wycieczek w Tatrach pewnego turysty A:\n",
    "\n",
    "| LP | pogoda     | sezon letni | pora dnia  | cel wycieczki |\n",
    "| -- | ---------- | ----------- | ---------- | ------------- |\n",
    "| 1  | słonecznie | tak         | rano       | szczyt        |\n",
    "| 2  | słonecznie | nie         | rano       | dolina        |\n",
    "| 3  | wietrznie  | tak         | rano       | szczyt        |\n",
    "| 4  | deszczowo  | tak         | popołudnie | szczyt        |\n",
    "| 5  | deszczowo  | nie         | rano       | Krupówki      |\n",
    "| 6  | deszczowo  | tak         | rano       | szczyt        |\n",
    "| 7  | wietrznie  | nie         | popołudnie | szczyt        |\n",
    "| 8  | wietrznie  | nie         | rano       | Morskie Oko   |\n",
    "| 9  | wietrznie  | tak         | rano       | szczyt        |\n",
    "| 10 | słonecznie | nie         | rano       | dolina        |\n",
    "\n",
    "Na podstawie tej bazy wiedzy można zbudować drzewo decyzyjne obrazujace schemat podejmowania decyzji przez turystę A.\n",
    "\n",
    "Pierwszym krokiem budowy drzewa decyzyjnego będzie wyznaczenie atrybutu zachowującego największy zysk informacyjny:\n",
    "\n",
    "$$ Entropy(S) = -p(szczyt) log_2 p(szczyt) - p(dolina) log_2 p(dolina) - p(Morskie Oko) log_2 p(Morskie Oko) - p(Krupówki) log_2 p(Krupówki) = $$\n",
    "$$ = -\\frac{6}{10} log_2 \\frac{6}{10} - \\frac{2}{10} log_2 \\frac{2}{10} - \\frac{1}{10} log_2 \\frac{1}{10} - \\frac{1}{10} log_2 \\frac{1}{10} = $$\n",
    "$$ = -\\frac{6}{10} * -0.737 - \\frac{2}{10} * -2.322 - \\frac{1}{10} * -3.322 - \\frac{1}{10} * -3.322 = $$\n",
    "$$ = 0.4422 + 0.4644 + 0.3322 + 0.3322 = 1.571 $$\n",
    "\n",
    "$$ Gain(S, Pogoda) = 1.571 - \\frac{|S_{słonecznie}|}{10} Entropy(S_{słonecznie}) - \\frac{|S_{wietrznie}|}{10} Entropy(S_{wietrznie}) - \\frac{|S_{deszczowo}|}{10} Entropy(S_{deszczowo}) = $$\n",
    "$$ = 1.571 - 0.3 * 0.918 - 0.4 * 0.81125 - 0.3 * 0.918 = 0.70 $$\n",
    "\n",
    "$$ Gain(S, sezon letni) = 0.61 $$\n",
    "\n",
    "$$ Gain(S, pora dnia) = 0.2816 $$\n",
    "\n",
    "Zatem korzeniem drzewa zostanie atrybut pogoda i od tego węzła należy wyprowadzić tyle krawędzi ile jest wartości w atrybucie:\n",
    "\n",
    "![root](img/tatry_root.png)\n",
    "\n",
    "Po utworzeniu korzenia drzewa należy przyjrzeć się klasom decyzyjnym przypisanym wartościom atrybutu $$S_{słonecznie}$$.\n",
    "Są to klasy {szczyt, dolina}, zatem krawędź $$S_{słonecznie}$$ nie zakończy się liściem drzewa decyzyjnego.\n",
    "W tym celu należy wybrać kolejny atrybut, który rozdzieli obiekty należące do tego podzbioru.\n",
    "\n",
    "Podobnie sytuacja wygląda w przypadku podzbioru $$S_{wietrznie}$$.\n",
    "\n",
    "W tym celu należy wyznaczyć zysk informacyjny dla obiektów znajdujących się w podzbiorach gałęzi oraz atrybutów z wyjątkiem użytego przy budowie korzenia drzewa decyzyjnego.\n",
    "Przy wyznaczaniu zysków informacyjnych należy brać pod uwagę tylko te atrybuty, które nie zostały wykorzystane w podziale wyższych poziomów drzewa decyzyjnego.\n",
    "\n",
    "Rozważmy podzbiór obiektów dla odgałęzienia $$S_{słonecznie}$$\n",
    "\n",
    "| LP | pogoda     | sezon letni | pora dnia  | cel wycieczki |\n",
    "| -- | ---------- | ----------- | ---------- | ------------- |\n",
    "| 1  | słonecznie | tak         | rano       | szczyt        |\n",
    "| 2  | słonecznie | nie         | rano       | dolina        |\n",
    "| 10 | słonecznie | nie         | rano       | dolina        |\n",
    "\n",
    "$$ Entropy(S_{słonecznie}) = 0.918 $$\n",
    "$$ Gain(S_{słonecznie}, sezon letni) = 0.918 - \\frac{|S_{tak}|}{|S|} Entropy(S_{tak}) - \\frac{|S_{nie}|}{|S|} Entropy(S_{nie}) = $$\n",
    "$$ 0.918 - \\frac{1}{3} * 0 - \\frac{2}{3} * 0 = 0.918 $$\n",
    "\n",
    "$$ Gain(S_{słonecznie}, pora dnia) = 0 $$\n",
    "\n",
    "Zatem do podziału podzbioru $$ S_{słonecznie} $$ użyjemy atrybutu \"sezon letni\", który zachowuje większy zysk informacyjny.\n",
    "Atrybut \"pora dnia\" dla tego podzbioru nie wnosi żadnej wartości.\n",
    "\n",
    "Drzewo decyzyjne po podziale podzbioru $$ S_{słonecznie} $$ będzie wyglądało następująco:\n",
    "\n",
    "![node_2](img/tatry_node_2.png)\n",
    "\n",
    "Powtarzając powyższy schemat można zbudować pełne drzewo decyzyjne, które dla przedstawionego systemu decyzyjnego prezentuje się następująco:\n",
    "\n",
    "![full_tree_tatras](img/tatry_full.png)\n",
    "\n",
    "### Zadanie\n",
    "\n",
    "Zbudować drzewo decyzyjne na podstawie następującego systemu decyzyjnego:\n",
    "\n",
    "| Outlook  | Temp | Humidity | Windy | Play |\n",
    "| -------- | ---- | -------- | ----- | ---- |\n",
    "| Rainy    | Hot  | High     | f     | no   |\n",
    "| Rainy\t   | Hot  | High     | t\t | no   |\n",
    "| Overcast | Hot  | High\t | f     | yes  |\n",
    "| Sunny    | Mild |\tHigh     | f     | yes  |\n",
    "| Sunny    | Cool | Normal   | f     | yes  |\n",
    "| Sunny    | Cool | Normal   | t     | no   |\n",
    "| Overcast | Cool | Normal   | t     | yes  |\n",
    "| Rainy    | Mild |\tHigh     | f     | no   |\n",
    "| Rainy    | Cool |\tNormal   | f\t | yes  |\n",
    "| Sunny    | Mild |\tNormal\t | f     | yes  |\n",
    "| Rainy    | Mild |\tNormal\t | t\t | yes  |\n",
    "| Overcast | Mild | High     | t     | yes  |\n",
    "| Overcast | Hot  | Normal   | f     | yes  |\n",
    "| Sunny    | Mild | High     | t     | no   |\n",
    "\n",
    "Do narysowania drzewa można wykorzystać narzędzie https://app.diagrams.net\n",
    "\n",
    "## Precyzja i czułość\n",
    "\n",
    "Miary precyzji i czułości pozwalają na określenie jak klasyfikator radzi sobie z trafnością przydzielanych decyzji, co można wyrazić następującymi wzorami:\n",
    "\n",
    "$$Precision = \\frac{TP}{TP + FP}$$\n",
    "$$Sensitivity = \\frac{TP}{TP + FN}$$\n",
    "$$Accuracy = \\frac{TP + TN}{Total}$$\n",
    "\n",
    "gdzie:\n",
    "- TP oznacza liczbę obiektów poprawnie sklasyfikowanych jako pozytywne\n",
    "- TN oznacza liczbę obiektów poprawnie sklasyfikowanych jako negatywne\n",
    "- FP oznacza liczbę obiektów fałszywie sklasyfikowanych jako pozytywne\n",
    "- FN oznacza liczbę obiektów fałszywie sklasyfikowanych jako negatywne\n",
    "\n",
    "Za pomocą precyzji można określić trafność klasyfikacji, czyli odsetek wszystkich pozytywnych obiektów, które zostały poprawnie sklasyfikowane.\n",
    "Czułość służy do określania trafności wyszukiwania wszystkich pozytywnych obiektów, czyli odsetka obiektów sklasyfikowanych jako pozytywne spośród wszystkich pozytywnych obiektów.\n",
    "\n",
    "## Drzewo decyzyjne w pakiecie Scikit learn\n",
    "\n",
    "Pakiet Scikit learn udostępnia implementacje drzewa decyzyjnego zarówno jako predyktora w procesie klasyfikacji, jak i regresji.\n",
    "\n",
    "### Klasyfikacja przy użyciu drzewa decyzyjnego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Wczytanie systemu decyzyjnego"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "   glucose  bloodpressure  diabetes\n0       40             85         0\n1       40             92         0\n2       45             63         1\n3       45             80         0\n4       40             73         1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>glucose</th>\n      <th>bloodpressure</th>\n      <th>diabetes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>40</td>\n      <td>85</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>40</td>\n      <td>92</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>45</td>\n      <td>63</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>45</td>\n      <td>80</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>40</td>\n      <td>73</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/data-samples.csv')\n",
    "\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Utworzenie obiektu klasyfikatora"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "5-krotna walidacja krzyżowa dokładności modelu drzewa decyzyjnego"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.96482412, 0.90954774, 0.91457286, 0.90452261, 0.92964824])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(clf, df.iloc[:, 0:2], df.iloc[:, 2], cv=5)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Regresja przy użyciu drzewa decyzyjnego\n",
    "\n",
    "W celu zbudowania regresora metodą drzewa decyzyjnego należy utworzyć obiekt klasy DecisionTreeRegressor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "regressor = DecisionTreeRegressor()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Zadania\n",
    "\n",
    "1. Korzystając ze źródła http://archive.ics.uci.edu/ml/datasets.php wybrać dowolny system decyzyjny z binarnym atrybutem decyzyjnym, a następnie dokonać\n",
    "klasyfikacji przy użyciu drzewa decyzyjnego z pakietu Scikit learn. Sprawdzić następujące parametry klasyfikacji za pomocą 5-krotnej walidacji krzyżowej:\n",
    "    - dokładność\n",
    "    - precyzja\n",
    "    - czułość\n",
    "\n",
    "2. Korzystając ze źródła http://archive.ics.uci.edu/ml/datasets.php wybrać zbiór danych z przeznaczeniem regresyjnym.\n",
    "Sprawdzić przy użyciu 10-krotnej walidacji krzyżowej MAE modelu na wybranym zbiorze.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}